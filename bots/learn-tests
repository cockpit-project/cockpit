#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# This file is part of Cockpit.
#
# Copyright (C) 2017 Slavek Kabrda
#
# Cockpit is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation; either version 2.1 of the License, or
# (at your option) any later version.
#
# Cockpit is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with Cockpit; If not, see <http://www.gnu.org/licenses/>.

# The name and version of the training data
TRAINING_DATA = "tests-train-1.jsonl.gz"

# The number of days in history to learn from. This is different from
# the amount of  data we gather in tests-data, and can be adjusted
# independently.
SINCE = 21

import gzip
import os
import subprocess
import sys
import tempfile
import time

sys.dont_write_bytecode = True

import task
import learn.data

BOTS = os.path.dirname(os.path.realpath(__file__))
DATA = os.path.join(os.environ.get("TEST_DATA", BOTS), "images")

def run(training_data, verbose=False, dry=False, **kwargs):
    upload = [ os.path.join(BOTS, "image-upload"), "--state" ]

    # Default set of training data, retrieve it and use from DATA directory
    if not training_data:
        training_data = TRAINING_DATA
    if "/" not in training_data and not os.path.exists(training_data):
        if not dry:
            subprocess.check_call([ os.path.join(BOTS, "image-download"), "--state", training_data ])
        training_data = os.path.join(DATA, training_data)
    items = loader(training_data, verbose)

    # Train for the second model
    path = train(items, verbose)

    # Or do the upload if a real run
    if not dry:
        subprocess.check_call(upload + [ path ])


# Load jsonl style data into items, or if no file specified
# then just run tests-data to retrieve live data
def loader(training_data, verbose):
    items = [ ]

    # The input file exists
    exists = training_data and os.path.exists(training_data)

    # Dry mode just read a file
    proc = None
    if not exists:
        raise RuntimeError("learn-tests: the input file doesn't exist: {0}".format(training_data))
    inp = gzip.open(training_data, 'rb')
    if verbose:
        sys.stderr.write("Loading tests data\n")

    since = time.strftime("%Y-%m-%d", time.gmtime(time.time() - (86400 * SINCE)))

    def only(item):
        if not learn.data.failures(item):
            return False
        date = item.get("date", "")
        return date > since

    try:
        items = list(learn.data.load(inp, only=only, verbose=verbose))
    finally:
        if proc:
            proc.wait()
            if proc.returncode != 0:
                raise RuntimeError("tests-data command failed")
        inp.close()

    return items

def train(items, verbose):
    import learn.cluster
    model = learn.cluster.Model(verbose=verbose)
    model.train(items)

    directory = tempfile.mkdtemp(prefix="clusters-")
    if verbose:
        sys.stderr.write("{0}: Dumping clusters\n".format(directory))
    model.dump(directory)
    for filename in os.listdir(directory):
        task.attach(os.path.join(directory, filename))

    return learn.cluster.save(DATA, model)

if __name__ == '__main__':
    task.main(function=run, title="Learn from testing data", verbose=True)
